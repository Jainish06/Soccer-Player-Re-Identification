{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdce60f7-1aad-48c7-90be-4428b2f85fbd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pip install ultralytics opencv-python numpy pandas matplotlib seaborn scikit-learn torch tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96095746-2ea2-4bd3-9fac-38844723be95",
   "metadata": {
    "panel-layout": {
     "height": 0,
     "visible": true,
     "width": 100
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "import seaborn as sns\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from scipy.spatial.distance import cdist\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "import os\n",
    "from collections import defaultdict, deque\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a5e991-bb0b-402d-828f-ba4b1a3a1d66",
   "metadata": {
    "panel-layout": {
     "height": 0,
     "visible": true,
     "width": 100
    }
   },
   "outputs": [],
   "source": [
    "# Set up plotting\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd645c7-e682-473c-b1d3-5a5e13874a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlayerTracker:\n",
    "    \"\"\"\n",
    "    Advanced player tracking system for cross-camera mapping\n",
    "    \"\"\"\n",
    "    def __init__(self, max_disappeared=30, max_distance=100):\n",
    "        self.next_id = 0\n",
    "        self.objects = {}\n",
    "        self.disappeared = {}\n",
    "        self.max_disappeared = max_disappeared\n",
    "        self.max_distance = max_distance\n",
    "        \n",
    "    def register(self, centroid, bbox, features):\n",
    "        \"\"\"Register a new player with unique ID\"\"\"\n",
    "        self.objects[self.next_id] = {\n",
    "            'centroid': centroid,\n",
    "            'bbox': bbox,\n",
    "            'features': features,\n",
    "            'history': deque(maxlen=30)\n",
    "        }\n",
    "        self.disappeared[self.next_id] = 0\n",
    "        self.next_id += 1\n",
    "        \n",
    "    def deregister(self, object_id):\n",
    "        \"\"\"Remove player from tracking\"\"\"\n",
    "        del self.objects[object_id]\n",
    "        del self.disappeared[object_id]\n",
    "        \n",
    "    def update(self, detections):\n",
    "        \"\"\"Update tracker with new detections\"\"\"\n",
    "        if len(detections) == 0:\n",
    "            # Mark all existing objects as disappeared\n",
    "            for object_id in list(self.disappeared.keys()):\n",
    "                self.disappeared[object_id] += 1\n",
    "                if self.disappeared[object_id] > self.max_disappeared:\n",
    "                    self.deregister(object_id)\n",
    "            return\n",
    "            \n",
    "        # Initialize arrays for new detections\n",
    "        input_centroids = []\n",
    "        input_bboxes = []\n",
    "        input_features = []\n",
    "        \n",
    "        for detection in detections:\n",
    "            input_centroids.append(detection['centroid'])\n",
    "            input_bboxes.append(detection['bbox'])\n",
    "            input_features.append(detection['features'])\n",
    "            \n",
    "        # If no existing objects, register all as new\n",
    "        if len(self.objects) == 0:\n",
    "            for i in range(len(input_centroids)):\n",
    "                self.register(input_centroids[i], input_bboxes[i], input_features[i])\n",
    "        else:\n",
    "            # Match existing objects to new detections\n",
    "            object_centroids = [obj['centroid'] for obj in self.objects.values()]\n",
    "            object_ids = list(self.objects.keys())\n",
    "            \n",
    "            # Compute distance matrix\n",
    "            D = cdist(np.array(object_centroids), np.array(input_centroids))\n",
    "            \n",
    "            # Hungarian algorithm for optimal assignment\n",
    "            row_ind, col_ind = linear_sum_assignment(D)\n",
    "            \n",
    "            used_row_indices = set()\n",
    "            used_col_indices = set()\n",
    "            \n",
    "            # Update matched objects\n",
    "            for (row, col) in zip(row_ind, col_ind):\n",
    "                if D[row, col] <= self.max_distance:\n",
    "                    object_id = object_ids[row]\n",
    "                    self.objects[object_id]['centroid'] = input_centroids[col]\n",
    "                    self.objects[object_id]['bbox'] = input_bboxes[col]\n",
    "                    self.objects[object_id]['features'] = input_features[col]\n",
    "                    self.objects[object_id]['history'].append(input_centroids[col])\n",
    "                    self.disappeared[object_id] = 0\n",
    "                    \n",
    "                    used_row_indices.add(row)\n",
    "                    used_col_indices.add(col)\n",
    "                    \n",
    "            # Handle unmatched detections and objects\n",
    "            unused_row_indices = set(range(0, D.shape[0])).difference(used_row_indices)\n",
    "            unused_col_indices = set(range(0, D.shape[1])).difference(used_col_indices)\n",
    "            \n",
    "            # Mark unmatched existing objects as disappeared\n",
    "            for row in unused_row_indices:\n",
    "                object_id = object_ids[row]\n",
    "                self.disappeared[object_id] += 1\n",
    "                if self.disappeared[object_id] > self.max_disappeared:\n",
    "                    self.deregister(object_id)\n",
    "                    \n",
    "            # Register new objects\n",
    "            for col in unused_col_indices:\n",
    "                self.register(input_centroids[col], input_bboxes[col], input_features[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759ad21b-2f4a-46c0-8bc0-3800e4fbe88b",
   "metadata": {
    "panel-layout": {
     "height": 448.8125,
     "visible": true,
     "width": 100
    }
   },
   "outputs": [],
   "source": [
    "class CrossCameraMapper:\n",
    "    \"\"\"\n",
    "    Main class for mapping players across different camera views\n",
    "    \"\"\"\n",
    "    def __init__(self, model_path):\n",
    "        self.model = YOLO(model_path)\n",
    "        self.broadcast_tracker = PlayerTracker()\n",
    "        self.tacticam_tracker = PlayerTracker()\n",
    "        self.player_mappings = {}\n",
    "        \n",
    "    def extract_features(self, frame, bbox):\n",
    "        \"\"\"Extract visual features from player bounding box\"\"\"\n",
    "        x1, y1, x2, y2 = map(int, bbox)\n",
    "        \n",
    "        # Ensure coordinates are within frame bounds\n",
    "        h, w = frame.shape[:2]\n",
    "        x1, y1 = max(0, x1), max(0, y1)\n",
    "        x2, y2 = min(w, x2), min(h, y2)\n",
    "        \n",
    "        if x2 <= x1 or y2 <= y1:\n",
    "            return np.zeros(10)  # Return zero features for invalid bbox\n",
    "            \n",
    "        player_roi = frame[y1:y2, x1:x2]\n",
    "        \n",
    "        if player_roi.size == 0:\n",
    "            return np.zeros(10)\n",
    "            \n",
    "        # Color histogram features\n",
    "        hist_b = cv2.calcHist([player_roi], [0], None, [32], [0, 256])\n",
    "        hist_g = cv2.calcHist([player_roi], [1], None, [32], [0, 256])\n",
    "        hist_r = cv2.calcHist([player_roi], [2], None, [32], [0, 256])\n",
    "        \n",
    "        # Normalize histograms\n",
    "        hist_b = hist_b.flatten() / (hist_b.sum() + 1e-6)\n",
    "        hist_g = hist_g.flatten() / (hist_g.sum() + 1e-6)\n",
    "        hist_r = hist_r.flatten() / (hist_r.sum() + 1e-6)\n",
    "        \n",
    "        # Spatial features\n",
    "        aspect_ratio = (x2 - x1) / (y2 - y1) if (y2 - y1) > 0 else 1.0\n",
    "        area = (x2 - x1) * (y2 - y1)\n",
    "        \n",
    "        # Combine features\n",
    "        features = np.concatenate([\n",
    "            hist_b[:8],  # Reduced histogram size\n",
    "            hist_g[:8],\n",
    "            hist_r[:8],\n",
    "            [aspect_ratio, area / (frame.shape[0] * frame.shape[1])]  # Normalized area\n",
    "        ])\n",
    "        \n",
    "        return features[:10]  # Ensure fixed feature size\n",
    "        \n",
    "    def detect_players(self, frame, debug=False):\n",
    "        \"\"\"Detect players in frame using YOLO model with proper class filtering\"\"\"\n",
    "        results = self.model(frame, verbose=False)\n",
    "        detections = []\n",
    "        \n",
    "        # Debug: Print all detected classes and their names\n",
    "        if debug and hasattr(self.model, 'names'):\n",
    "            print(f\"Model classes: {self.model.names}\")\n",
    "        \n",
    "        for result in results:\n",
    "            boxes = result.boxes\n",
    "            if boxes is not None:\n",
    "                if debug:\n",
    "                    print(f\"Found {len(boxes)} total detections\")\n",
    "                \n",
    "                for i, box in enumerate(boxes):\n",
    "                    # Get box coordinates and confidence\n",
    "                    x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()\n",
    "                    conf = box.conf[0].cpu().numpy()\n",
    "                    cls = int(box.cls[0].cpu().numpy())\n",
    "                    \n",
    "                    if debug:\n",
    "                        class_name = self.model.names.get(cls, f\"class_{cls}\") if hasattr(self.model, 'names') else f\"class_{cls}\"\n",
    "                        print(f\"Detection {i}: class={cls} ({class_name}), conf={conf:.3f}, bbox=({x1:.1f},{y1:.1f},{x2:.1f},{y2:.1f})\")\n",
    "                    \n",
    "                    # Filter for player classes - try multiple possible class indices\n",
    "                    # Common class indices for players: 0 (person), 1 (player), etc.\n",
    "                    player_classes = [1,2,3]  # Add more class indices if needed\n",
    "                    ball_classes = [0]  # Common ball class indices (ball, sports ball, etc.)\n",
    "                    \n",
    "                    # Check if this is a player class (not ball)\n",
    "                    is_player = cls in player_classes or (cls not in ball_classes and conf > 0.3)\n",
    "                    \n",
    "                    # Also filter by size - players should be reasonably sized\n",
    "                    width = x2 - x1\n",
    "                    height = y2 - y1\n",
    "                    area = width * height\n",
    "                    aspect_ratio = height / width if width > 0 else 0\n",
    "                    \n",
    "                    # Player size filters (adjust based on your video resolution)\n",
    "                    min_area = 500  # Minimum pixel area for a player\n",
    "                    max_area = frame.shape[0] * frame.shape[1] * 0.3  # Max 30% of frame\n",
    "                    min_aspect_ratio = 1.2  # Players are usually taller than wide\n",
    "                    max_aspect_ratio = 4.0  # But not too tall\n",
    "                    \n",
    "                    size_filter = (min_area < area < max_area and \n",
    "                                 min_aspect_ratio < aspect_ratio < max_aspect_ratio)\n",
    "                    \n",
    "                    if conf > 0.3 and is_player and size_filter:\n",
    "                        centroid = ((x1 + x2) / 2, (y1 + y2) / 2)\n",
    "                        bbox = (x1, y1, x2, y2)\n",
    "                        features = self.extract_features(frame, bbox)\n",
    "                        \n",
    "                        detections.append({\n",
    "                            'centroid': centroid,\n",
    "                            'bbox': bbox,\n",
    "                            'features': features,\n",
    "                            'confidence': conf,\n",
    "                            'class': cls,\n",
    "                            'area': area,\n",
    "                            'aspect_ratio': aspect_ratio\n",
    "                        })\n",
    "                        \n",
    "                        if debug:\n",
    "                            print(f\"âœ“ Accepted as player: class={cls}, conf={conf:.3f}, area={area:.0f}, aspect_ratio={aspect_ratio:.2f}\")\n",
    "                    elif debug:\n",
    "                        reasons = []\n",
    "                        if conf <= 0.3:\n",
    "                            reasons.append(f\"low_conf({conf:.3f})\")\n",
    "                        if not is_player:\n",
    "                            reasons.append(f\"not_player_class({cls})\")\n",
    "                        if not size_filter:\n",
    "                            reasons.append(f\"size_filter(area={area:.0f},ar={aspect_ratio:.2f})\")\n",
    "                        print(f\"âœ— Rejected: {', '.join(reasons)}\")\n",
    "        \n",
    "        if debug:\n",
    "            print(f\"Final detections: {len(detections)} players\")\n",
    "            \n",
    "        return detections\n",
    "    \n",
    "    def process_video(self, video_path, tracker, max_frames=None, visualize=True, output_path=None, debug_first_frame=True):\n",
    "        \"\"\"Process video and track players with optional visualization and debugging\"\"\"\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        frame_count = 0\n",
    "        results = []\n",
    "        \n",
    "        # Get video properties\n",
    "        fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        \n",
    "        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        if max_frames:\n",
    "            total_frames = min(total_frames, max_frames)\n",
    "        \n",
    "        # Setup video writer for output if requested\n",
    "        video_writer = None\n",
    "        if visualize and output_path:\n",
    "            fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "            video_writer = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "            \n",
    "        pbar = tqdm(total=total_frames, desc=f\"Processing {os.path.basename(video_path)}\")\n",
    "        \n",
    "        # Define colors for different player IDs\n",
    "        colors = [\n",
    "            (255, 0, 0), (0, 255, 0), (0, 0, 255), (255, 255, 0), (255, 0, 255),\n",
    "            (0, 255, 255), (128, 0, 128), (255, 165, 0), (0, 128, 128), (128, 128, 0),\n",
    "            (255, 192, 203), (0, 255, 127), (255, 20, 147), (32, 178, 170), (255, 69, 0)\n",
    "        ]\n",
    "        \n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret or (max_frames and frame_count >= max_frames):\n",
    "                break\n",
    "            \n",
    "            # Debug first frame to understand what's being detected\n",
    "            debug_mode = debug_first_frame and frame_count == 0\n",
    "            if debug_mode:\n",
    "                print(f\"\\n=== DEBUGGING FIRST FRAME of {os.path.basename(video_path)} ===\")\n",
    "                \n",
    "            # Detect players\n",
    "            detections = self.detect_players(frame, debug=debug_mode)\n",
    "            \n",
    "            if debug_mode:\n",
    "                print(f\"=== END DEBUG FIRST FRAME ===\\n\")\n",
    "                \n",
    "            # Update tracker\n",
    "            tracker.update(detections)\n",
    "            \n",
    "            # Create visualization frame\n",
    "            vis_frame = frame.copy()\n",
    "            \n",
    "            # Draw all raw detections first (for debugging)\n",
    "            if visualize:\n",
    "                # Draw raw YOLO detections in light blue\n",
    "                raw_results = self.model(frame, verbose=False)\n",
    "                for result in raw_results:\n",
    "                    boxes = result.boxes\n",
    "                    if boxes is not None:\n",
    "                        for box in boxes:\n",
    "                            x1, y1, x2, y2 = map(int, box.xyxy[0].cpu().numpy())\n",
    "                            conf = box.conf[0].cpu().numpy()\n",
    "                            cls = int(box.cls[0].cpu().numpy())\n",
    "                            \n",
    "                            # Draw all detections in light blue\n",
    "                            cv2.rectangle(vis_frame, (x1, y1), (x2, y2), (173, 216, 230), 1)\n",
    "                            \n",
    "                            # Label with class and confidence\n",
    "                            class_name = self.model.names.get(cls, f\"c{cls}\") if hasattr(self.model, 'names') else f\"c{cls}\"\n",
    "                            label = f\"{class_name}:{conf:.2f}\"\n",
    "                            cv2.putText(vis_frame, label, (x1, y1-5), \n",
    "                                       cv2.FONT_HERSHEY_SIMPLEX, 0.4, (173, 216, 230), 1)\n",
    "            \n",
    "            # Draw tracked players (filtered detections) in bright colors\n",
    "            for player_id, player_data in tracker.objects.items():\n",
    "                x1, y1, x2, y2 = map(int, player_data['bbox'])\n",
    "                centroid = player_data['centroid']\n",
    "                \n",
    "                # Get color for this player ID\n",
    "                color = colors[player_id % len(colors)]\n",
    "                \n",
    "                # Draw bounding box (thick)\n",
    "                cv2.rectangle(vis_frame, (x1, y1), (x2, y2), color, 3)\n",
    "                \n",
    "                # Draw centroid\n",
    "                cv2.circle(vis_frame, (int(centroid[0]), int(centroid[1])), 5, color, -1)\n",
    "                \n",
    "                # Draw player ID\n",
    "                label = f\"Player {player_id}\"\n",
    "                label_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.7, 2)[0]\n",
    "                cv2.rectangle(vis_frame, (x1, y1 - label_size[1] - 10), \n",
    "                             (x1 + label_size[0], y1), color, -1)\n",
    "                cv2.putText(vis_frame, label, (x1, y1 - 5), \n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "                \n",
    "                # Draw trajectory (if available)\n",
    "                if len(player_data['history']) > 1:\n",
    "                    points = np.array(player_data['history'], dtype=np.int32)\n",
    "                    cv2.polylines(vis_frame, [points], False, color, 2)\n",
    "            \n",
    "            # Add comprehensive frame info\n",
    "            info_lines = [\n",
    "                f\"Frame: {frame_count} | Tracked Players: {len(tracker.objects)}\",\n",
    "                f\"Raw Detections: {len(detections)} | Video: {os.path.basename(video_path)}\"\n",
    "            ]\n",
    "            \n",
    "            for i, info_text in enumerate(info_lines):\n",
    "                cv2.putText(vis_frame, info_text, (10, 30 + i*25), \n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)\n",
    "            \n",
    "            # Add legend\n",
    "            legend_y = height - 60\n",
    "            cv2.putText(vis_frame, \"Light Blue: All YOLO detections\", (10, legend_y), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (173, 216, 230), 2)\n",
    "            cv2.putText(vis_frame, \"Bright Colors: Tracked Players\", (10, legend_y + 20), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n",
    "            \n",
    "            # Display frame if visualizing\n",
    "            if visualize:\n",
    "                # Resize for display if too large\n",
    "                display_frame = vis_frame\n",
    "                if width > 1280:\n",
    "                    scale = 1280 / width\n",
    "                    new_width = int(width * scale)\n",
    "                    new_height = int(height * scale)\n",
    "                    display_frame = cv2.resize(vis_frame, (new_width, new_height))\n",
    "                \n",
    "                cv2.imshow(f'Tracking - {os.path.basename(video_path)}', display_frame)\n",
    "                \n",
    "                # Press 'q' to quit, 'p' to pause, 'd' for debug info\n",
    "                key = cv2.waitKey(1) & 0xFF\n",
    "                if key == ord('q'):\n",
    "                    break\n",
    "                elif key == ord('p'):\n",
    "                    cv2.waitKey(0)  # Wait for any key to continue\n",
    "                elif key == ord('d'):\n",
    "                    # Print debug info for current frame\n",
    "                    print(f\"\\n=== DEBUG INFO Frame {frame_count} ===\")\n",
    "                    debug_detections = self.detect_players(frame, debug=True)\n",
    "                    print(f\"=== END DEBUG INFO ===\\n\")\n",
    "            \n",
    "            # Write frame to output video\n",
    "            if video_writer:\n",
    "                video_writer.write(vis_frame)\n",
    "            \n",
    "            # Store results\n",
    "            frame_data = {\n",
    "                'frame': frame_count,\n",
    "                'players': {}\n",
    "            }\n",
    "            \n",
    "            for player_id, player_data in tracker.objects.items():\n",
    "                frame_data['players'][player_id] = {\n",
    "                    'centroid': player_data['centroid'],\n",
    "                    'bbox': player_data['bbox'],\n",
    "                    'features': player_data['features']\n",
    "                }\n",
    "                \n",
    "            results.append(frame_data)\n",
    "            frame_count += 1\n",
    "            pbar.update(1)\n",
    "            \n",
    "        cap.release()\n",
    "        if video_writer:\n",
    "            video_writer.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        pbar.close()\n",
    "        return results\n",
    "    \n",
    "    def compute_feature_similarity(self, features1, features2):\n",
    "        \"\"\"Compute similarity between feature vectors\"\"\"\n",
    "        # Handle zero features\n",
    "        if np.all(features1 == 0) or np.all(features2 == 0):\n",
    "            return 0.0\n",
    "            \n",
    "        # Cosine similarity\n",
    "        dot_product = np.dot(features1, features2)\n",
    "        norm1 = np.linalg.norm(features1)\n",
    "        norm2 = np.linalg.norm(features2)\n",
    "        \n",
    "        if norm1 == 0 or norm2 == 0:\n",
    "            return 0.0\n",
    "            \n",
    "        return dot_product / (norm1 * norm2)\n",
    "    \n",
    "    def map_players_across_cameras(self, broadcast_results, tacticam_results):\n",
    "        \"\"\"Map players between broadcast and tacticam views\"\"\"\n",
    "        print(\"Mapping players across cameras...\")\n",
    "        \n",
    "        # Collect all player features from both cameras\n",
    "        broadcast_features = defaultdict(list)\n",
    "        tacticam_features = defaultdict(list)\n",
    "        \n",
    "        # Extract features for each player across all frames\n",
    "        for frame_data in broadcast_results:\n",
    "            for player_id, player_data in frame_data['players'].items():\n",
    "                broadcast_features[player_id].append(player_data['features'])\n",
    "                \n",
    "        for frame_data in tacticam_results:\n",
    "            for player_id, player_data in frame_data['players'].items():\n",
    "                tacticam_features[player_id].append(player_data['features'])\n",
    "        \n",
    "        # Compute average features for each player\n",
    "        broadcast_avg_features = {}\n",
    "        for player_id, features_list in broadcast_features.items():\n",
    "            if features_list:\n",
    "                broadcast_avg_features[player_id] = np.mean(features_list, axis=0)\n",
    "        \n",
    "        tacticam_avg_features = {}\n",
    "        for player_id, features_list in tacticam_features.items():\n",
    "            if features_list:\n",
    "                tacticam_avg_features[player_id] = np.mean(features_list, axis=0)\n",
    "        \n",
    "        # Create similarity matrix\n",
    "        broadcast_ids = list(broadcast_avg_features.keys())\n",
    "        tacticam_ids = list(tacticam_avg_features.keys())\n",
    "        \n",
    "        if not broadcast_ids or not tacticam_ids:\n",
    "            print(\"Warning: No players found in one or both videos\")\n",
    "            return {}\n",
    "        \n",
    "        similarity_matrix = np.zeros((len(broadcast_ids), len(tacticam_ids)))\n",
    "        \n",
    "        for i, b_id in enumerate(broadcast_ids):\n",
    "            for j, t_id in enumerate(tacticam_ids):\n",
    "                similarity = self.compute_feature_similarity(\n",
    "                    broadcast_avg_features[b_id],\n",
    "                    tacticam_avg_features[t_id]\n",
    "                )\n",
    "                similarity_matrix[i, j] = similarity\n",
    "        \n",
    "        # Use Hungarian algorithm to find optimal mapping\n",
    "        # Convert similarity to cost (distance)\n",
    "        cost_matrix = 1 - similarity_matrix\n",
    "        row_ind, col_ind = linear_sum_assignment(cost_matrix)\n",
    "        \n",
    "        # Create mappings\n",
    "        mappings = {}\n",
    "        for i, j in zip(row_ind, col_ind):\n",
    "            if similarity_matrix[i, j] > 0.3:  # Threshold for valid mapping\n",
    "                broadcast_id = broadcast_ids[i]\n",
    "                tacticam_id = tacticam_ids[j]\n",
    "                mappings[tacticam_id] = broadcast_id\n",
    "                \n",
    "        print(f\"Successfully mapped {len(mappings)} players\")\n",
    "        return mappings, similarity_matrix, broadcast_ids, tacticam_ids\n",
    "    \n",
    "    def visualize_mappings(self, similarity_matrix, broadcast_ids, tacticam_ids, mappings):\n",
    "        \"\"\"Visualize player mappings\"\"\"\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        \n",
    "        # Plot similarity matrix\n",
    "        plt.subplot(2, 2, 1)\n",
    "        sns.heatmap(similarity_matrix, \n",
    "                   xticklabels=[f'Tacticam_{id}' for id in tacticam_ids],\n",
    "                   yticklabels=[f'Broadcast_{id}' for id in broadcast_ids],\n",
    "                   annot=True, fmt='.2f', cmap='viridis')\n",
    "        plt.title('Player Similarity Matrix')\n",
    "        plt.xlabel('Tacticam Players')\n",
    "        plt.ylabel('Broadcast Players')\n",
    "        \n",
    "        # Plot mapping results\n",
    "        plt.subplot(2, 2, 2)\n",
    "        mapping_data = []\n",
    "        for tacticam_id, broadcast_id in mappings.items():\n",
    "            mapping_data.append({\n",
    "                'Tacticam_ID': tacticam_id,\n",
    "                'Broadcast_ID': broadcast_id,\n",
    "                'Similarity': similarity_matrix[broadcast_ids.index(broadcast_id), \n",
    "                                              tacticam_ids.index(tacticam_id)]\n",
    "            })\n",
    "        \n",
    "        if mapping_data:\n",
    "            df = pd.DataFrame(mapping_data)\n",
    "            bars = plt.bar(range(len(df)), df['Similarity'])\n",
    "            plt.xlabel('Player Pairs')\n",
    "            plt.ylabel('Similarity Score')\n",
    "            plt.title('Player Mapping Confidence')\n",
    "            plt.xticks(range(len(df)), \n",
    "                      [f'T{row.Tacticam_ID}â†’B{row.Broadcast_ID}' for _, row in df.iterrows()],\n",
    "                      rotation=45)\n",
    "            \n",
    "            # Color bars based on confidence\n",
    "            for bar, sim in zip(bars, df['Similarity']):\n",
    "                if sim > 0.7:\n",
    "                    bar.set_color('green')\n",
    "                elif sim > 0.5:\n",
    "                    bar.set_color('orange')\n",
    "                else:\n",
    "                    bar.set_color('red')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        return mapping_data if mapping_data else []\n",
    "    \n",
    "    def apply_consistent_ids(self, tacticam_results, mappings):\n",
    "        \"\"\"Apply consistent player IDs to tacticam results\"\"\"\n",
    "        print(\"Applying consistent player IDs...\")\n",
    "        \n",
    "        consistent_results = []\n",
    "        for frame_data in tacticam_results:\n",
    "            new_frame_data = {\n",
    "                'frame': frame_data['frame'],\n",
    "                'players': {}\n",
    "            }\n",
    "            \n",
    "            for tacticam_id, player_data in frame_data['players'].items():\n",
    "                # Get consistent ID from mapping\n",
    "                if tacticam_id in mappings:\n",
    "                    consistent_id = mappings[tacticam_id]\n",
    "                else:\n",
    "                    consistent_id = f\"unmapped_{tacticam_id}\"\n",
    "                \n",
    "                new_frame_data['players'][consistent_id] = player_data\n",
    "                \n",
    "            consistent_results.append(new_frame_data)\n",
    "            \n",
    "    def create_side_by_side_visualization(self, broadcast_video, tacticam_video, mappings, max_frames=300, output_path=\"mapped_tracking.mp4\"):\n",
    "        \"\"\"Create side-by-side video showing mapped players across both cameras\"\"\"\n",
    "        print(\"Creating side-by-side visualization with mapped players...\")\n",
    "        \n",
    "        # Open both videos\n",
    "        cap1 = cv2.VideoCapture(broadcast_video)\n",
    "        cap2 = cv2.VideoCapture(tacticam_video)\n",
    "        \n",
    "        # Get video properties\n",
    "        fps1 = int(cap1.get(cv2.CAP_PROP_FPS))\n",
    "        fps2 = int(cap2.get(cv2.CAP_PROP_FPS))\n",
    "        fps = min(fps1, fps2)  # Use minimum fps\n",
    "        \n",
    "        width1 = int(cap1.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        height1 = int(cap1.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        width2 = int(cap2.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        height2 = int(cap2.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        \n",
    "        # Make both frames same height\n",
    "        target_height = min(height1, height2)\n",
    "        scale1 = target_height / height1\n",
    "        scale2 = target_height / height2\n",
    "        new_width1 = int(width1 * scale1)\n",
    "        new_width2 = int(width2 * scale2)\n",
    "        \n",
    "        # Setup video writer\n",
    "        output_width = new_width1 + new_width2\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "        video_writer = cv2.VideoWriter(output_path, fourcc, fps, (output_width, target_height))\n",
    "        \n",
    "        # Reset trackers\n",
    "        self.broadcast_tracker = PlayerTracker()\n",
    "        self.tacticam_tracker = PlayerTracker()\n",
    "        \n",
    "        # Define consistent colors for mapped players\n",
    "        mapped_colors = {}\n",
    "        base_colors = [\n",
    "            (255, 0, 0), (0, 255, 0), (0, 0, 255), (255, 255, 0), (255, 0, 255),\n",
    "            (0, 255, 255), (128, 0, 128), (255, 165, 0), (0, 128, 128), (128, 128, 0),\n",
    "            (255, 192, 203), (0, 255, 127), (255, 20, 147), (32, 178, 170), (255, 69, 0)\n",
    "        ]\n",
    "        \n",
    "        frame_count = 0\n",
    "        pbar = tqdm(total=max_frames, desc=\"Creating side-by-side video\")\n",
    "        \n",
    "        while frame_count < max_frames:\n",
    "            ret1, frame1 = cap1.read()\n",
    "            ret2, frame2 = cap2.read()\n",
    "            \n",
    "            if not ret1 or not ret2:\n",
    "                break\n",
    "            \n",
    "            # Resize frames\n",
    "            frame1 = cv2.resize(frame1, (new_width1, target_height))\n",
    "            frame2 = cv2.resize(frame2, (new_width2, target_height))\n",
    "            \n",
    "            # Process both frames\n",
    "            detections1 = self.detect_players(frame1)\n",
    "            detections2 = self.detect_players(frame2)\n",
    "            \n",
    "            self.broadcast_tracker.update(detections1)\n",
    "            self.tacticam_tracker.update(detections2)\n",
    "            \n",
    "            # Draw tracking on broadcast frame\n",
    "            for player_id, player_data in self.broadcast_tracker.objects.items():\n",
    "                x1, y1, x2, y2 = map(int, player_data['bbox'])\n",
    "                centroid = player_data['centroid']\n",
    "                \n",
    "                # Use consistent color\n",
    "                if player_id not in mapped_colors:\n",
    "                    mapped_colors[player_id] = base_colors[len(mapped_colors) % len(base_colors)]\n",
    "                color = mapped_colors[player_id]\n",
    "                \n",
    "                # Draw bounding box and ID\n",
    "                cv2.rectangle(frame1, (x1, y1), (x2, y2), color, 2)\n",
    "                cv2.circle(frame1, (int(centroid[0]), int(centroid[1])), 5, color, -1)\n",
    "                \n",
    "                label = f\"B{player_id}\"\n",
    "                cv2.rectangle(frame1, (x1, y1 - 25), (x1 + 50, y1), color, -1)\n",
    "                cv2.putText(frame1, label, (x1 + 5, y1 - 5), \n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "            \n",
    "            # Draw tracking on tacticam frame\n",
    "            for player_id, player_data in self.tacticam_tracker.objects.items():\n",
    "                x1, y1, x2, y2 = map(int, player_data['bbox'])\n",
    "                centroid = player_data['centroid']\n",
    "                \n",
    "                # Check if this player is mapped\n",
    "                mapped_id = mappings.get(player_id, None)\n",
    "                if mapped_id is not None and mapped_id in mapped_colors:\n",
    "                    color = mapped_colors[mapped_id]\n",
    "                    label = f\"T{player_id}â†’B{mapped_id}\"\n",
    "                else:\n",
    "                    color = (128, 128, 128)  # Gray for unmapped\n",
    "                    label = f\"T{player_id}\"\n",
    "                \n",
    "                # Draw bounding box and ID\n",
    "                cv2.rectangle(frame2, (x1, y1), (x2, y2), color, 2)\n",
    "                cv2.circle(frame2, (int(centroid[0]), int(centroid[1])), 5, color, -1)\n",
    "                \n",
    "                label_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2)[0]\n",
    "                cv2.rectangle(frame2, (x1, y1 - 25), (x1 + label_size[0] + 10, y1), color, -1)\n",
    "                cv2.putText(frame2, label, (x1 + 5, y1 - 5), \n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)\n",
    "            \n",
    "            # Add titles\n",
    "            cv2.putText(frame1, \"BROADCAST VIEW\", (10, 30), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "            cv2.putText(frame2, \"TACTICAM VIEW\", (10, 30), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "            \n",
    "            # Add frame counter\n",
    "            cv2.putText(frame1, f\"Frame: {frame_count}\", (10, target_height - 20), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "            cv2.putText(frame2, f\"Mapped: {len(mappings)} players\", (10, target_height - 20), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "            \n",
    "            # Combine frames side by side\n",
    "            combined_frame = np.hstack([frame1, frame2])\n",
    "            \n",
    "            # Write to output video\n",
    "            video_writer.write(combined_frame)\n",
    "            \n",
    "            frame_count += 1\n",
    "            pbar.update(1)\n",
    "        \n",
    "        # Cleanup\n",
    "        cap1.release()\n",
    "        cap2.release()\n",
    "        video_writer.release()\n",
    "        pbar.close()\n",
    "        \n",
    "        print(f\"âœ“ Side-by-side video saved as '{output_path}'\")\n",
    "        return output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a919e212-84e0-4a15-b32c-ca653b1ee523",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main execution function\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to execute cross-camera player mapping\n",
    "    \"\"\"\n",
    "    print(\"=== Cross-Camera Player Mapping System ===\\n\")\n",
    "    \n",
    "    # Configuration\n",
    "    MODEL_PATH = \"best.pt\"  # Update with actual model path\n",
    "    BROADCAST_VIDEO = \"broadcast.mp4\"\n",
    "    TACTICAM_VIDEO = \"tacticam.mp4\"\n",
    "    MAX_FRAMES = 300  # Process first 300 frames for demonstration\n",
    "    \n",
    "    # Initialize mapper\n",
    "    print(\"1. Initializing Cross-Camera Mapper...\")\n",
    "    try:\n",
    "        mapper = CrossCameraMapper(MODEL_PATH)\n",
    "        print(\"âœ“ Model loaded successfully\")\n",
    "    except Exception as e:\n",
    "        print(f\"âœ— Failed to load model: {e}\")\n",
    "        print(\"Please download the model from the provided Google Drive link\")\n",
    "        return\n",
    "    \n",
    "    # Process videos with visualization\n",
    "    print(\"\\n2. Processing Videos with Live Tracking Visualization...\")\n",
    "    try:\n",
    "        print(\"Processing broadcast video...\")\n",
    "        print(\"Controls: Press 'q' to quit, 'p' to pause\")\n",
    "        broadcast_results = mapper.process_video(BROADCAST_VIDEO, \n",
    "                                                mapper.broadcast_tracker, \n",
    "                                                MAX_FRAMES,\n",
    "                                                visualize=True,\n",
    "                                                output_path=\"broadcast_tracked.mp4\")\n",
    "        \n",
    "        print(\"Processing tacticam video...\")\n",
    "        print(\"Controls: Press 'q' to quit, 'p' to pause\")\n",
    "        tacticam_results = mapper.process_video(TACTICAM_VIDEO, \n",
    "                                               mapper.tacticam_tracker, \n",
    "                                               MAX_FRAMES,\n",
    "                                               visualize=True,\n",
    "                                               output_path=\"tacticam_tracked.mp4\")\n",
    "        \n",
    "        print(\"âœ“ Video processing completed\")\n",
    "        print(\"âœ“ Tracked videos saved as 'broadcast_tracked.mp4' and 'tacticam_tracked.mp4'\")\n",
    "    except Exception as e:\n",
    "        print(f\"âœ— Failed to process videos: {e}\")\n",
    "        return\n",
    "    \n",
    "    # Map players across cameras\n",
    "    print(\"\\n3. Mapping Players Across Cameras...\")\n",
    "    try:\n",
    "        mappings, similarity_matrix, broadcast_ids, tacticam_ids = mapper.map_players_across_cameras(\n",
    "            broadcast_results, tacticam_results)\n",
    "        \n",
    "        print(\"âœ“ Player mapping completed\")\n",
    "        print(f\"Found {len(mappings)} player correspondences\")\n",
    "        \n",
    "        # Display mappings\n",
    "        print(\"\\nPlayer Mappings:\")\n",
    "        for tacticam_id, broadcast_id in mappings.items():\n",
    "            print(f\"  Tacticam Player {tacticam_id} â†’ Broadcast Player {broadcast_id}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"âœ— Failed to map players: {e}\")\n",
    "        return\n",
    "    \n",
    "    # Visualize results\n",
    "    print(\"\\n4. Visualizing Results...\")\n",
    "    try:\n",
    "        mapping_data = mapper.visualize_mappings(similarity_matrix, broadcast_ids, \n",
    "                                                tacticam_ids, mappings)\n",
    "        \n",
    "        # Apply consistent IDs\n",
    "        consistent_tacticam_results = mapper.apply_consistent_ids(tacticam_results, mappings)\n",
    "        \n",
    "        print(\"âœ“ Visualization completed\")\n",
    "        \n",
    "        # Create side-by-side comparison video\n",
    "        print(\"\\n4.1. Creating Side-by-Side Mapped Video...\")\n",
    "        try:\n",
    "            side_by_side_path = mapper.create_side_by_side_visualization(\n",
    "                BROADCAST_VIDEO, TACTICAM_VIDEO, mappings, MAX_FRAMES)\n",
    "            print(\"âœ“ Side-by-side video created successfully\")\n",
    "        except Exception as e:\n",
    "            print(f\"âœ— Failed to create side-by-side video: {e}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âœ— Failed to visualize results: {e}\")\n",
    "        return\n",
    "    \n",
    "    # Save results\n",
    "    print(\"\\n5. Saving Results...\")\n",
    "    try:\n",
    "        # Save mappings to JSON\n",
    "        output_data = {\n",
    "            'mappings': mappings,\n",
    "            'mapping_confidence': mapping_data,\n",
    "            'total_frames_processed': len(broadcast_results),\n",
    "            'broadcast_players': len(set(broadcast_ids)),\n",
    "            'tacticam_players': len(set(tacticam_ids))\n",
    "        }\n",
    "        \n",
    "        with open('player_mappings.json', 'w') as f:\n",
    "            json.dump(output_data, f, indent=2, default=str)\n",
    "            \n",
    "        print(\"âœ“ Results saved to 'player_mappings.json'\")\n",
    "        \n",
    "        # Print summary statistics\n",
    "        print(f\"\\n=== Summary ===\")\n",
    "        print(f\"Frames processed: {len(broadcast_results)}\")\n",
    "        print(f\"Broadcast players detected: {len(broadcast_ids)}\")\n",
    "        print(f\"Tacticam players detected: {len(tacticam_ids)}\")\n",
    "        print(f\"Successful mappings: {len(mappings)}\")\n",
    "        \n",
    "        if mapping_data:\n",
    "            avg_confidence = np.mean([item['Similarity'] for item in mapping_data])\n",
    "            print(f\"Average mapping confidence: {avg_confidence:.3f}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âœ— Failed to save results: {e}\")\n",
    "    \n",
    "    print(\"\\n=== Cross-Camera Player Mapping Complete ===\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9dda083-fcf3-4c8c-b7ec-3f4852da9fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_with_visualization():\n",
    "    \"\"\"\n",
    "    Enhanced version with real-time visualization and video output\n",
    "    \"\"\"\n",
    "    print(\"=== Cross-Camera Player Mapping with Live Visualization ===\\n\")\n",
    "    \n",
    "    # Configuration\n",
    "    MODEL_PATH = \"best.pt\"  # Update with actual model path\n",
    "    BROADCAST_VIDEO = \"broadcast.mp4\"\n",
    "    TACTICAM_VIDEO = \"tacticam.mp4\"\n",
    "    MAX_FRAMES = 300  # Process first 300 frames for demonstration\n",
    "    \n",
    "    # Initialize mapper\n",
    "    print(\"1. Initializing Cross-Camera Mapper...\")\n",
    "    try:\n",
    "        mapper = CrossCameraMapper(MODEL_PATH)\n",
    "        print(\"âœ“ Model loaded successfully\")\n",
    "    except Exception as e:\n",
    "        print(f\"âœ— Failed to load model: {e}\")\n",
    "        print(\"Please download the model from the provided Google Drive link\")\n",
    "        return\n",
    "    \n",
    "    # Process videos with real-time visualization\n",
    "    print(\"\\n2. Processing Videos with Live Tracking...\")\n",
    "    print(\"ðŸ“º Live tracking windows will open - use 'q' to quit, 'p' to pause\")\n",
    "    print(\"ðŸŽ¥ Output videos will be saved automatically\")\n",
    "    \n",
    "    try:\n",
    "        # Process broadcast video with live visualization\n",
    "        print(\"\\nProcessing broadcast video...\")\n",
    "        broadcast_results = mapper.process_video(\n",
    "            BROADCAST_VIDEO, \n",
    "            mapper.broadcast_tracker, \n",
    "            MAX_FRAMES,\n",
    "            visualize=True,\n",
    "            output_path=\"broadcast_tracked.mp4\"\n",
    "        )\n",
    "        \n",
    "        # Reset tracker for tacticam\n",
    "        mapper.tacticam_tracker = PlayerTracker()\n",
    "        \n",
    "        # Process tacticam video with live visualization\n",
    "        print(\"\\nProcessing tacticam video...\")\n",
    "        tacticam_results = mapper.process_video(\n",
    "            TACTICAM_VIDEO, \n",
    "            mapper.tacticam_tracker, \n",
    "            MAX_FRAMES,\n",
    "            visualize=True,\n",
    "            output_path=\"tacticam_tracked.mp4\"\n",
    "        )\n",
    "        \n",
    "        print(\"âœ“ Individual tracking videos saved\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âœ— Failed to process videos: {e}\")\n",
    "        return\n",
    "    \n",
    "    # Map players across cameras\n",
    "    print(\"\\n3. Mapping Players Across Cameras...\")\n",
    "    try:\n",
    "        mappings, similarity_matrix, broadcast_ids, tacticam_ids = mapper.map_players_across_cameras(\n",
    "            broadcast_results, tacticam_results)\n",
    "        \n",
    "        print(\"âœ“ Player mapping completed\")\n",
    "        print(f\"Found {len(mappings)} player correspondences\")\n",
    "        \n",
    "        # Display mappings\n",
    "        print(\"\\nPlayer Mappings:\")\n",
    "        for tacticam_id, broadcast_id in mappings.items():\n",
    "            print(f\"  Tacticam Player {tacticam_id} â†’ Broadcast Player {broadcast_id}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"âœ— Failed to map players: {e}\")\n",
    "        return\n",
    "    \n",
    "    # Create visualizations\n",
    "    print(\"\\n4. Creating Final Visualizations...\")\n",
    "    try:\n",
    "        mapping_data = mapper.visualize_mappings(similarity_matrix, broadcast_ids, \n",
    "                                                tacticam_ids, mappings)\n",
    "        \n",
    "        # Create side-by-side comparison video\n",
    "        print(\"\\n4.1. Creating Side-by-Side Mapped Video...\")\n",
    "        side_by_side_path = mapper.create_side_by_side_visualization(\n",
    "            BROADCAST_VIDEO, TACTICAM_VIDEO, mappings, MAX_FRAMES)\n",
    "        \n",
    "        print(\"âœ“ All visualizations completed\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âœ— Failed to create visualizations: {e}\")\n",
    "        return\n",
    "    \n",
    "    # Save results\n",
    "    print(\"\\n5. Saving Results...\")\n",
    "    try:\n",
    "        output_data = {\n",
    "            'mappings': mappings,\n",
    "            'mapping_confidence': mapping_data,\n",
    "            'total_frames_processed': len(broadcast_results),\n",
    "            'broadcast_players': len(set(broadcast_ids)),\n",
    "            'tacticam_players': len(set(tacticam_ids)),\n",
    "            'output_files': {\n",
    "                'broadcast_tracked': 'broadcast_tracked.mp4',\n",
    "                'tacticam_tracked': 'tacticam_tracked.mp4',\n",
    "                'side_by_side': side_by_side_path\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        with open('player_mappings_with_videos.json', 'w') as f:\n",
    "            json.dump(output_data, f, indent=2, default=str)\n",
    "            \n",
    "        print(\"âœ“ Results saved to 'player_mappings_with_videos.json'\")\n",
    "        \n",
    "        # Print summary\n",
    "        print(f\"\\n=== Output Files Created ===\")\n",
    "        print(f\"ðŸ“¹ Individual tracked videos:\")\n",
    "        print(f\"  - broadcast_tracked.mp4 (Broadcast view with player tracking)\")\n",
    "        print(f\"  - tacticam_tracked.mp4 (Tacticam view with player tracking)\")\n",
    "        print(f\"ðŸ“º Combined visualization:\")\n",
    "        print(f\"  - {side_by_side_path} (Side-by-side with mapped players)\")\n",
    "        print(f\"ðŸ“Š Analysis results:\")\n",
    "        print(f\"  - player_mappings_with_videos.json (Detailed mapping data)\")\n",
    "        \n",
    "        print(f\"\\n=== Summary Statistics ===\")\n",
    "        print(f\"Frames processed: {len(broadcast_results)}\")\n",
    "        print(f\"Broadcast players detected: {len(broadcast_ids)}\")\n",
    "        print(f\"Tacticam players detected: {len(tacticam_ids)}\")\n",
    "        print(f\"Successful mappings: {len(mappings)}\")\n",
    "        \n",
    "        if mapping_data:\n",
    "            avg_confidence = np.mean([item['Similarity'] for item in mapping_data])\n",
    "            print(f\"Average mapping confidence: {avg_confidence:.3f}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âœ— Failed to save results: {e}\")\n",
    "    \n",
    "    print(\"\\n=== Cross-Camera Player Mapping with Visualization Complete ===\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ecf867-57c1-4a57-b52b-eadd7db93268",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quick_test_tracking():\n",
    "    \"\"\"\n",
    "    Quick test function to verify tracking on a single video\n",
    "    \"\"\"\n",
    "    print(\"=== Quick Tracking Test ===\\n\")\n",
    "    \n",
    "    MODEL_PATH = \"best.pt\"\n",
    "    TEST_VIDEO = \"broadcast.mp4\"  # Change to your test video\n",
    "    \n",
    "    try:\n",
    "        mapper = CrossCameraMapper(MODEL_PATH)\n",
    "        print(\"âœ“ Model loaded successfully\")\n",
    "        \n",
    "        print(f\"\\nðŸŽ¥ Testing tracking on {TEST_VIDEO}\")\n",
    "        print(\"Press 'q' to quit, 'p' to pause during playback\")\n",
    "        \n",
    "        results = mapper.process_video(\n",
    "            TEST_VIDEO,\n",
    "            PlayerTracker(),\n",
    "            max_frames=100,  # Test with 100 frames\n",
    "            visualize=True,\n",
    "            output_path=\"test_tracking.mp4\"\n",
    "        )\n",
    "        \n",
    "        print(f\"âœ“ Test completed! Output saved as 'test_tracking.mp4'\")\n",
    "        print(f\"Processed {len(results)} frames\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âœ— Test failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bdf0701-3df2-4bed-9b3f-f35c8e6ad5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def debug_model_classes():\n",
    "    \"\"\"\n",
    "    Debug function to understand what the YOLO model detects\n",
    "    \"\"\"\n",
    "    print(\"=== YOLO Model Class Debugging ===\\n\")\n",
    "    \n",
    "    MODEL_PATH = \"best.pt\"\n",
    "    TEST_VIDEO = \"broadcast.mp4\"  # Change to your test video\n",
    "    \n",
    "    try:\n",
    "        # Load model\n",
    "        model = YOLO(MODEL_PATH)\n",
    "        print(\"âœ“ Model loaded successfully\")\n",
    "        \n",
    "        # Print model information\n",
    "        if hasattr(model, 'names'):\n",
    "            print(f\"\\nModel classes: {model.names}\")\n",
    "            print(f\"Number of classes: {len(model.names)}\")\n",
    "        else:\n",
    "            print(\"Warning: Model doesn't have class names attribute\")\n",
    "        \n",
    "        # Test on first frame\n",
    "        cap = cv2.VideoCapture(TEST_VIDEO)\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        if not ret:\n",
    "            print(f\"âœ— Could not read from {TEST_VIDEO}\")\n",
    "            return\n",
    "            \n",
    "        print(f\"\\nTesting on first frame of {TEST_VIDEO}\")\n",
    "        print(f\"Frame shape: {frame.shape}\")\n",
    "        \n",
    "        # Run inference\n",
    "        results = model(frame, verbose=False)\n",
    "        \n",
    "        print(f\"\\nAll detections found:\")\n",
    "        detection_count = {}\n",
    "        \n",
    "        for result in results:\n",
    "            boxes = result.boxes\n",
    "            if boxes is not None:\n",
    "                print(f\"Total detections: {len(boxes)}\")\n",
    "                \n",
    "                for i, box in enumerate(boxes):\n",
    "                    x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()\n",
    "                    conf = box.conf[0].cpu().numpy()\n",
    "                    cls = int(box.cls[0].cpu().numpy())\n",
    "                    \n",
    "                    # Get class name\n",
    "                    class_name = model.names.get(cls, f\"unknown_class_{cls}\") if hasattr(model, 'names') else f\"class_{cls}\"\n",
    "                    \n",
    "                    # Calculate size info\n",
    "                    width = x2 - x1\n",
    "                    height = y2 - y1\n",
    "                    area = width * height\n",
    "                    aspect_ratio = height / width if width > 0 else 0\n",
    "                    \n",
    "                    print(f\"  {i+1}. Class: {cls} ({class_name})\")\n",
    "                    print(f\"      Confidence: {conf:.3f}\")\n",
    "                    print(f\"      BBox: ({x1:.1f}, {y1:.1f}, {x2:.1f}, {y2:.1f})\")\n",
    "                    print(f\"      Size: {width:.1f}x{height:.1f} (area={area:.0f})\")\n",
    "                    print(f\"      Aspect ratio: {aspect_ratio:.2f}\")\n",
    "                    print()\n",
    "                    \n",
    "                    # Count detections by class\n",
    "                    if class_name not in detection_count:\n",
    "                        detection_count[class_name] = 0\n",
    "                    detection_count[class_name] += 1\n",
    "            else:\n",
    "                print(\"No detections found!\")\n",
    "        \n",
    "        print(f\"Detection summary:\")\n",
    "        for class_name, count in detection_count.items():\n",
    "            print(f\"  {class_name}: {count} detections\")\n",
    "            \n",
    "        cap.release()\n",
    "        \n",
    "        # Recommendations\n",
    "        print(f\"\\n=== RECOMMENDATIONS ===\")\n",
    "        print(\"Based on the detections above, you should:\")\n",
    "        print(\"1. Identify which class represents 'players' (usually 'person' or 'player')\")\n",
    "        print(\"2. Identify which class represents 'ball' (usually 'ball' or 'sports ball')\")\n",
    "        print(\"3. Update the player_classes and ball_classes lists in detect_players()\")\n",
    "        print(\"\\nExample fixes:\")\n",
    "        if 'person' in detection_count:\n",
    "            print(\"  - If 'person' are your players, set player_classes = [class_id_for_person]\")\n",
    "        if 'ball' in detection_count:\n",
    "            print(\"  - If 'ball' is the ball, add its class_id to ball_classes\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âœ— Debug failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d97b654-55a5-4482-b4c1-6e9312d44162",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quick_test_with_debug():\n",
    "    \"\"\"\n",
    "    Quick test with comprehensive debugging\n",
    "    \"\"\"\n",
    "    print(\"=== Quick Test with Debug Mode ===\\n\")\n",
    "    \n",
    "    MODEL_PATH = \"best.pt\"\n",
    "    TEST_VIDEO = \"broadcast.mp4\"  # Change to your test video\n",
    "    \n",
    "    try:\n",
    "        mapper = CrossCameraMapper(MODEL_PATH)\n",
    "        print(\"âœ“ Model loaded successfully\")\n",
    "        \n",
    "        print(f\"\\nðŸŽ¥ Testing tracking on {TEST_VIDEO} with debug mode\")\n",
    "        print(\"Controls:\")\n",
    "        print(\"  - Press 'q' to quit\")\n",
    "        print(\"  - Press 'p' to pause\") \n",
    "        print(\"  - Press 'd' to show debug info for current frame\")\n",
    "        print(\"\\nThe video will show:\")\n",
    "        print(\"  - Light blue boxes: All YOLO detections\")\n",
    "        print(\"  - Bright colored boxes: Successfully tracked players\")\n",
    "        \n",
    "        results = mapper.process_video(\n",
    "            TEST_VIDEO,\n",
    "            PlayerTracker(),\n",
    "            max_frames=50,  # Test with 50 frames\n",
    "            visualize=True,\n",
    "            output_path=\"debug_tracking.mp4\",\n",
    "            debug_first_frame=True  # This will show detailed debug info for first frame\n",
    "        )\n",
    "        \n",
    "        print(f\"\\nâœ“ Test completed!\")\n",
    "        print(f\"Processed {len(results)} frames\")\n",
    "        \n",
    "        # Count players found\n",
    "        total_players = set()\n",
    "        for frame_data in results:\n",
    "            total_players.update(frame_data['players'].keys())\n",
    "        \n",
    "        print(f\"Total unique players tracked: {len(total_players)}\")\n",
    "        if len(total_players) == 0:\n",
    "            print(\"\\nâŒ NO PLAYERS TRACKED!\")\n",
    "            print(\"This means the class filtering is wrong.\")\n",
    "            print(\"Run debug_model_classes() to see what the model actually detects.\")\n",
    "        else:\n",
    "            print(f\"âœ… Successfully tracked players: {list(total_players)}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âœ— Test failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95bce96f-f43e-4a7f-8d08-66869fa0546d",
   "metadata": {
    "panel-layout": {
     "height": 0,
     "visible": true,
     "width": 100
    }
   },
   "outputs": [],
   "source": [
    "debug_model_classes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba18d532-11e9-481e-997d-3ba2fc600fdc",
   "metadata": {
    "panel-layout": {
     "height": 0,
     "visible": true,
     "width": 100
    }
   },
   "outputs": [],
   "source": [
    "quick_test_with_debug()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3f130d-c8a8-4036-8fa5-2b4fcd042fd1",
   "metadata": {
    "panel-layout": {
     "height": 0,
     "visible": true,
     "width": 100
    }
   },
   "outputs": [],
   "source": [
    "quick_test_tracking()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6513139-0820-475f-9cbb-91d7b15c7312",
   "metadata": {
    "panel-layout": {
     "height": 0,
     "visible": true,
     "width": 100
    }
   },
   "outputs": [],
   "source": [
    "run_with_visualization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a12a068-3ee0-4825-a341-f9c078bff30f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "panel-cell-order": [
   "96095746-2ea2-4bd3-9fac-38844723be95",
   "40a5e991-bb0b-402d-828f-ba4b1a3a1d66",
   "040a82e0-6aaa-488e-8ce1-f5a7aa25aa9c",
   "95bce96f-f43e-4a7f-8d08-66869fa0546d",
   "ba18d532-11e9-481e-997d-3ba2fc600fdc",
   "3b3f130d-c8a8-4036-8fa5-2b4fcd042fd1",
   "a6513139-0820-475f-9cbb-91d7b15c7312"
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
